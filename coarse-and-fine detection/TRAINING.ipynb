{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-b2mGWtN_O9M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\" #please put your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mcD-O_Yp_1p2",
    "outputId": "f9e69dc9-91da-42ef-cf32-3fe4ebcd5aeb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24mIY10y_2f4",
    "outputId": "38d021fa-17a3-4024-dbdc-4f2ae3a0b198"
   },
   "outputs": [],
   "source": [
    "# %cd 'drive/MyDrive/Image Perception (Personal)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Toxr3bBCAI8O",
    "outputId": "cb005cfd-bbe3-4b23-ca97-a43389fdd217"
   },
   "outputs": [],
   "source": [
    "# !dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wqdsC6xg_O9R"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, MaxPool2D, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, SGD\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from keras.regularizers import l2\n",
    "# from io_ import score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gsKTvYcd_O9S",
    "outputId": "a5601073-7e50-4c21-b54c-61a5675ab143"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ6hJsDv_O9T"
   },
   "source": [
    "## Splitting data into train, test, val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FRZyfvmx_O9T"
   },
   "outputs": [],
   "source": [
    "# data_dir = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObKyWBroArk0",
    "outputId": "8b58b9db-0f4e-44e9-e80d-d55f46060931"
   },
   "outputs": [],
   "source": [
    "# !pip install split-folders tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHjCrjqH_O9U",
    "outputId": "eea104d3-effa-4543-b00d-a4b294d8a7cf"
   },
   "outputs": [],
   "source": [
    "# import splitfolders  # or import split_folders  #split into train, test, val\n",
    "\n",
    "# # Split with a ratio.\n",
    "# # To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "# splitfolders.ratio(data_dir, output=\"Splitteddata/\", seed=1337, ratio=(.8, .1, .1), group_prefix=None) # default values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adp_t3N6_O9U"
   },
   "source": [
    "## Loading data & data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ragmuBT6_O9U"
   },
   "outputs": [],
   "source": [
    "imagedatagenerator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20, \n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True, \n",
    "    fill_mode=\"nearest\", rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "g0yrckZ7_O9V"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "img_height = 225\n",
    "img_width = 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wZUbuPqj_O9V"
   },
   "outputs": [],
   "source": [
    "train_dir = 'Splitteddata/train'\n",
    "val_dir = 'Splitteddata/val'\n",
    "test_dir = 'Splitteddata/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CWizAPh_O9V",
    "outputId": "1c3ef65f-da8a-4eb7-c2b1-0ab65f8dc89f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24186 images belonging to 72 classes.\n"
     ]
    }
   ],
   "source": [
    "#training and validation (to be splitted later on)\n",
    "train_ds = imagedatagenerator.flow_from_directory(\n",
    "                                                train_dir,\n",
    "                                                target_size=(img_height, img_width),\n",
    "                                                color_mode=\"rgb\",\n",
    "                                                classes=None,\n",
    "                                                class_mode=\"sparse\",\n",
    "                                                batch_size= batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                seed=123,\n",
    "                                                save_to_dir='Augmented Images',\n",
    "                                                save_prefix=\"\",\n",
    "                                                save_format=\"jpg\",\n",
    "                                                follow_links=False,\n",
    "                                                interpolation=\"nearest\",\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4fPOfHpI_O9W"
   },
   "outputs": [],
   "source": [
    "\n",
    "# for _ in range(5):\n",
    "#     img, label = train_ds.next()\n",
    "#     print(img.shape)\n",
    "#     print(img)#  (1,256,256,3)\n",
    "#     plt.imshow(img[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyOdaA5__O9W",
    "outputId": "c63f530a-4abd-44be-8823-72aee3fd5a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2999 images belonging to 72 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = imagedatagenerator.flow_from_directory(\n",
    "                                                val_dir,\n",
    "                                                target_size=(img_height, img_width),\n",
    "                                                color_mode=\"rgb\",\n",
    "                                                classes=None,\n",
    "                                                class_mode=\"sparse\",\n",
    "                                                batch_size= batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                seed=123,\n",
    "                                                save_to_dir='Augmented Images',\n",
    "                                                save_prefix=\"\",\n",
    "                                                save_format=\"jpg\",\n",
    "                                                follow_links=False,\n",
    "                                                interpolation=\"nearest\",\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWxC6e56_O9W"
   },
   "source": [
    "## Model and Training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7BWCEDY_O9X",
    "outputId": "fb5121da-1d75-4e0b-fddd-265d4b5845e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 2048)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 72)                3686472   \n",
      "=================================================================\n",
      "Total params: 25,489,256\n",
      "Trainable params: 25,454,824\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 72\n",
    "\n",
    "# #MODEL 3\n",
    "# Write your code here\n",
    "inceptionv3 = InceptionV3(input_shape = (225,225,3), weights='imagenet', include_top=False)\n",
    "model = Sequential()\n",
    "model.add(inceptionv3)\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(\n",
    "    units= num_classes, \n",
    "    kernel_initializer='glorot_uniform', \n",
    "    kernel_regularizer=l2(.0005),\n",
    "    activation='softmax'))\n",
    "\n",
    "\n",
    "# model.add(Dense(units=72, activation=\"softmax\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-QzPXeqf_O9X"
   },
   "outputs": [],
   "source": [
    "# Define your optimizer here\n",
    "# optim = SGD(lr=1e-3)\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer=optim,\n",
    "#               metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy(k = 1), 'accuracy'])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer=SGD(lr=0.01, momentum=0.9),\n",
    "    metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(k = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "uAyr92aZ_O9X",
    "outputId": "3fc0f1d0-314e-4141-8440-f5e5a308bcf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "189/189 [==============================] - 2678s 14s/step - loss: 3.2361 - accuracy: 0.3194 - sparse_top_k_categorical_accuracy: 0.5620 - val_loss: 3.2565 - val_accuracy: 0.2454 - val_sparse_top_k_categorical_accuracy: 0.5905\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.25647, saving model to siti(27).h5\n",
      "Epoch 2/3\n",
      "189/189 [==============================] - 2746s 14s/step - loss: 0.9859 - accuracy: 0.7314 - sparse_top_k_categorical_accuracy: 0.9522 - val_loss: 1.2541 - val_accuracy: 0.6822 - val_sparse_top_k_categorical_accuracy: 0.9256\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.25647 to 1.25409, saving model to siti(27).h5\n",
      "Epoch 3/3\n",
      "189/189 [==============================] - 2420s 13s/step - loss: 0.6412 - accuracy: 0.8336 - sparse_top_k_categorical_accuracy: 0.9835 - val_loss: 1.1664 - val_accuracy: 0.7039 - val_sparse_top_k_categorical_accuracy: 0.9386\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25409 to 1.16638, saving model to siti(27).h5\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='siti(27).h5', \n",
    "                                                mode='min', \n",
    "                                                monitor='val_loss', \n",
    "                                                verbose=2, \n",
    "                                                save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=2,\n",
    "                          verbose=2,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=1,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [checkpoint,\n",
    "                  earlystop,\n",
    "                  reduce_lr]\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit(train_ds, verbose = 1, # split data in 80-20 sets\n",
    "                    epochs = epochs,\n",
    "                    validation_data = val_ds,\n",
    "                    batch_size = batch_size, callbacks = callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkM9H16g_O9Y"
   },
   "source": [
    "## Saving Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SBKYV4j6_O9Y"
   },
   "outputs": [],
   "source": [
    "# save your model and weight (only submit best model)\n",
    "best_model = model\n",
    "model_json = best_model.to_json()\n",
    "with open(\"Siti(27).json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "best_model.save_weights('Siti(27).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmpZE-jS_O9Z",
    "outputId": "5effefd0-39c5-4cdb-8868-83a4e050de48"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uR4IVBg6SQ_k",
    "outputId": "b2cd6652-688a-4aa0-c60c-d783bce1b282"
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBZHrN7bYpFc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "TRAINING (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
